{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Trong phần này, chúng ta thử kết hợp kết quả của bài thực hành [trước](https://github.com/dangkh/face_detection/blob/master/EigenfacesRecognitionWithSVM.ipynb) với neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import function and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from time import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features: 1850\n",
      "n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features: %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute a PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the top 150 eigenfaces from 966 faces\n",
      "done in 0.286s\n",
      "Projecting the input data on the eigenfaces orthonormal basis\n",
      "done in 0.023s\n"
     ]
    }
   ],
   "source": [
    "n_components = 150\n",
    "\n",
    "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "      % (n_components, X_train.shape[0]))\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(X_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "eigenfaces = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(966, 150)\n",
      "(966,)\n",
      "(966, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pca.shape)\n",
    "print(y_train.shape)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "print(y_train.shape)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              154624    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 161,799\n",
      "Trainable params: 161,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim=150, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "epochs = 20\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "966/966 [==============================] - 0s - loss: 1.5757 - acc: 0.4607     \n",
      "Epoch 2/20\n",
      "966/966 [==============================] - 0s - loss: 0.6743 - acc: 0.8592     \n",
      "Epoch 3/20\n",
      "966/966 [==============================] - 0s - loss: 0.3342 - acc: 0.9586     \n",
      "Epoch 4/20\n",
      "966/966 [==============================] - 0s - loss: 0.1902 - acc: 0.9886     \n",
      "Epoch 5/20\n",
      "966/966 [==============================] - 0s - loss: 0.1241 - acc: 0.9959     \n",
      "Epoch 6/20\n",
      "966/966 [==============================] - 0s - loss: 0.0890 - acc: 0.9990     \n",
      "Epoch 7/20\n",
      "966/966 [==============================] - 0s - loss: 0.0675 - acc: 1.0000     \n",
      "Epoch 8/20\n",
      "966/966 [==============================] - 0s - loss: 0.0544 - acc: 1.0000     \n",
      "Epoch 9/20\n",
      "966/966 [==============================] - 0s - loss: 0.0450 - acc: 1.0000     \n",
      "Epoch 10/20\n",
      "966/966 [==============================] - 0s - loss: 0.0384 - acc: 1.0000     \n",
      "Epoch 11/20\n",
      "966/966 [==============================] - 0s - loss: 0.0333 - acc: 1.0000     \n",
      "Epoch 12/20\n",
      "966/966 [==============================] - 0s - loss: 0.0294 - acc: 1.0000     \n",
      "Epoch 13/20\n",
      "966/966 [==============================] - 0s - loss: 0.0264 - acc: 1.0000     \n",
      "Epoch 14/20\n",
      "966/966 [==============================] - 0s - loss: 0.0239 - acc: 1.0000     \n",
      "Epoch 15/20\n",
      "966/966 [==============================] - 0s - loss: 0.0218 - acc: 1.0000     \n",
      "Epoch 16/20\n",
      "966/966 [==============================] - 0s - loss: 0.0200 - acc: 1.0000     \n",
      "Epoch 17/20\n",
      "966/966 [==============================] - 0s - loss: 0.0185 - acc: 1.0000     \n",
      "Epoch 18/20\n",
      "966/966 [==============================] - 0s - loss: 0.0172 - acc: 1.0000     - ETA: 0s - loss: 0.0173 - acc: 1.000\n",
      "Epoch 19/20\n",
      "966/966 [==============================] - 0s - loss: 0.0162 - acc: 1.0000     \n",
      "Epoch 20/20\n",
      "966/966 [==============================] - 0s - loss: 0.0152 - acc: 1.0000     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4686ef1dd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pca, y_train, epochs=epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 7)\n",
      "(322, 150)\n",
      "3\n",
      "[ 0.  0.  0.  1.  0.  0.  0.]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(y_test.shape)\n",
    "print(X_test_pca.shape)\n",
    "\n",
    "\n",
    "tmp = X_test_pca[1]\n",
    "tmp = tmp.reshape(1,150)\n",
    "print(np.argmax(model.predict(tmp)))\n",
    "print(y_test[1])\n",
    "\n",
    "\n",
    "## check 10 first test\n",
    "total = 0 \n",
    "for i in range(0,10):\n",
    "    tmp = X_test_pca[i]\n",
    "    tmp = tmp.reshape(1,150)\n",
    "    res = np.argmax(model.predict(tmp))\n",
    "    if y_test[i][res] == 1 :\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
